{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_50000.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws9T4cpaQytw",
        "colab_type": "code",
        "outputId": "aff3c818-9038-470c-d86e-ce646442a86a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "!pip install keras-tuner\n",
        "import sys\n",
        "import pickle\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "import kerastuner\n",
        "from kerastuner.tuners import RandomSearch, Hyperband\n",
        "from kerastuner import HyperModel\n",
        "import keras.metrics"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/f7/4b41b6832abf4c9bef71a664dc563adb25afc5812831667c6db572b1a261/keras-tuner-1.0.1.tar.gz (54kB)\n",
            "\r\u001b[K     |██████                          | 10kB 28.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.15.1)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.1-cp36-none-any.whl size=73200 sha256=303adeaa1bade5a3051f5d581a94774bdbbb3c61b07b4de3c8c2e393306112f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/cc/62/52716b70dd90f3db12519233c3a93a5360bc672da1a10ded43\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15356 sha256=4a0466f063adda9502e13ff4201ac5ef91fc82c730de6654bab5acce5b32f3a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.3 keras-tuner-1.0.1 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOBJBW_7Qov2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pickle.load(open('reviews_50000_processed.p', 'rb'))\n",
        "vocab = pickle.load(open('reviews_50000_vocab.p', 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIygiJmMQq27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fp = 'reviews_50000_tuned_cnn.p'\n",
        "NAME = 'tune_50000'\n",
        "\n",
        "CAT_COL = 'stars'\n",
        "\n",
        "num_reviews = len(df.index)\n",
        "\n",
        "train_num = int(num_reviews * .8)\n",
        "\n",
        "# Split into train / validate\n",
        "train = df.iloc[:train_num]\n",
        "validate = df.iloc[train_num:]\n",
        "\n",
        "X_train = train['text'].values\n",
        "# Convert [1-5] stars to a vector representation\n",
        "y_train = to_categorical(train[CAT_COL].values)\n",
        "print(y_train.shape)\n",
        "\n",
        "X_validate = validate['text'].values\n",
        "y_validate = to_categorical(validate[CAT_COL].values)\n",
        "print(y_validate.shape)\n",
        "\n",
        "max_length = max(max([len(review) for review in X_train]),  \n",
        "              max([len(review) for review in X_validate]))\n",
        "\n",
        "\n",
        "# Tokenizer() is a Keras object that tokenizes texts for pre-processing\n",
        "# Further processing is necessary before we can input the next into the CNN\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Tokenize the words -> assign and integer to each word and represent the review\n",
        "# as a sequence of integers\n",
        "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
        "X_validate_tokens = tokenizer.texts_to_sequences(X_validate)\n",
        "\n",
        "# Pad the vectors with zeros so that they're all the same length\n",
        "# Necessary for efficient computation\n",
        "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_length, padding='post')\n",
        "X_validate_pad = pad_sequences(X_validate_tokens, maxlen=max_length, padding='post')\n",
        "\n",
        "# Experiment design from \"A Sensitivity Analysis of (and Practitioners’ Guide to) Convolutional\n",
        "# Neural Networks for Sentence Classification\", Zhang and Wallace 2015, accessed via\n",
        "# the article found https://machinelearningmastery.com/best-practices-document-classification-deep-learning/\n",
        "# Tuner guidelines from https://keras-team.github.io/keras-tuner/ and https://www.sicara.ai/blog/hyperparameter-tuning-keras-tuner \n",
        "def build_model(hp):\n",
        "  global num_words\n",
        "  model = Sequential()\n",
        "  # Embedding layer - emebed the words into dense vectors (down from 5000+ feat. vectors)\n",
        "  # Parameters to tune: How many features the resulting dense vector has\n",
        "  model.add(Embedding(num_words, \n",
        "                      output_dim=hp.Choice('embedding_output_dimension', values=[50, 100, 150], default=100),\n",
        "                      input_length=max_length)) # experiment with size of vector space\n",
        "  # Convolution layer - tune the number of filters, kernel size, and activatin fxn\n",
        "  model.add(Conv1D(filters=hp.Choice('num_filters', values=[50, 100, 200, 400, 600],default=50),\n",
        "                    kernel_size=hp.Int('conv_kernel', min_value=1, max_value=10, step=1), \n",
        "                    activation=hp.Choice('conv_activ', values=['relu', 'tanh'], default='relu'))) # experiement with filter / kernel size / activation fxn\n",
        "  # Pooling layer to reduce convolution results\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  # Flatten to combine pooling results\n",
        "  model.add(Flatten())\n",
        "  # Dropout layer = tune the proportion\n",
        "  model.add(Dropout(rate=hp.Float('drop_rate', min_value=0, max_value=.5, step=.1)))\n",
        "  model.add(Dense(6, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam',  metrics=[keras.metrics.Precision(name='precision'),\n",
        "                  keras.metrics.Recall(name='recall')])\n",
        "  return model\n",
        "\n",
        "tuner = RandomSearch(\n",
        "          build_model,\n",
        "           metrics=[keras.metrics.Precision(name='precision'),\n",
        "             keras.metrics.Recall(name='recall')],\n",
        "          objective=kerastuner.Objective('val_precision', direction='max'),\n",
        "          max_trials=5,\n",
        "          executions_per_trial=3,\n",
        "          seed=10,\n",
        "          directory='tuning_out',\n",
        "          project_name=NAME)\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "# Tune the model\n",
        "tuner.search(X_train_pad, y_train, epochs=10, validation_data=(X_validate_pad, y_validate))\n",
        "\n",
        "tuner.results_summary()\n",
        "\n",
        "# Grab the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "model_json = best_model.to_json()\n",
        "open('reviews_10000_trained_cnn.json', 'w').write(model_json)\n",
        "best_model.save_weights('reviews_10000_trained_cnn_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfhDi2T2oKKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the training data and create testing data\n",
        "pickle.dump(X_train_pad, open('reviews_50000_X_train_pad.p', 'wb'))\n",
        "test = pickle.load(open('reviews_10000_test_processed.p', 'rb'))\n",
        "X_test_tokens = tokenizer.texts_to_sequences(test['text'].values)\n",
        "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_length, padding='post')\n",
        "pickle.dump(X_test_pad, open('reviews_50000_train_10000_test_pad.p', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js0lQH2soTOV",
        "colab_type": "code",
        "outputId": "cdf57e67-0cd6-403b-8c86-6f4da52f63aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Generate reports and save the prediction data\n",
        "from sklearn.metrics import classification_report\n",
        "test_report = classification_report(test['stars'], best_model.predict_classes(X_test_pad), output_dict=True)\n",
        "train_report = classification_report(train['stars'], best_model.predict_classes(X_train_pad), output_dict=True)\n",
        "open('cnn_50000_report.json', 'w').close()\n",
        "print(test_report, file=open('cnn_50000_report.json', 'a'))\n",
        "print(train_report, file=open('cnn_50000_report.json', 'a'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-a5bc4e890259>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}
